# with4gent v2.1 設計ドキュメント

## 1. 概要
`with4gent` は、LINE Messaging API と OpenAI Responses API を統合したインテリジェントなチャットボットです。
v2 では、以前のモノリシックな構造を廃止し、関心の分離（Separation of Concerns）に基づいたメンテナンス性の高いアーキテクチャに変更する。
v2.1 では、利便性の向上とプライバシー保護のための機能を追加する。

## 2. アーキテクチャ

### 2.1 構成図
アプリケーションは以下の主要レイヤーで構成する。

1.  **Web レイヤー (`src/main.py`)**:
    *   Flask を使用した Web サーバー。
    *   LINE Webhook の受信、署名検証、およびビジネスロジックへの委譲を担当。
    *   v2.1: `JoinEvent` のハンドラを追加。
2.  **ビジネスロジックレイヤー (`src/logic.py`)**:
    *   `ChatbotLogic` クラスが中心。
    *   メッセージの解析（メンション判定、コマンド判定、引用情報の抽出）、セッション管理、応答生成のフローを制御。
    *   v2.1: 匿名化処理 (`src/utils/anonymizer.py`) の統合。
3.  **サービスレイヤー (`src/services/`)**:
    *   外部 API との通信をカプセル化。
    *   `LineService`: LINE へのメッセージ送信、既読処理、グループ退出などを担当。v2.1: 文字数制限とメッセージ分割ロジックを追加。
    *   `OpenAIService`: OpenAI との通信、会話コンテキスト（履歴）の保持を担当。

### 2.2 データフロー
1.  LINE サーバーから Webhook (`/webhook`) を受信。
2.  `main.py` が署名を検証し、`ChatbotLogic` を呼び出す。
3.  `ChatbotLogic` が `LineService` を通じて既読処理を実行し、受信メッセージの `messageId` と `text` をインメモリキャッシュに格納。また、コンテキストごとの会話履歴（直近10件）にも追加。
4.  メッセージ内容を解析し、コマンド（`/exit` など）か通常対話かを判定。
5.  通常対話の場合、以下の情報を組み合わせて `OpenAIService` へのプロンプトを構成する。
    *   コンテキスト履歴（メンションされていない他ユーザーの発言を含む直近の会話の流れ）
    *   引用（リプライ元）テキスト（存在する場合）
    *   ユーザーの現在の入力メッセージ
6.  AI の応答に対しても匿名化を適用。
7.  `LineService` を通じてユーザーに返信。文字数が多い場合は（最大2分割の）自動分割を行う。

## 3. 主要機能

### 3.1 AI チャット & Web 検索
OpenAI の最新モデル（GPT-4o-mini）を使用し、自然な会話を提供する。必要に応じて AI が自動的に Web 検索を実行し、最新情報を取得して回答に反映させる。

### 3.2 セッション管理
`context_key`（ユーザーIDまたはグループ/ルームID）ごとに会話履歴を管理する。
*   個人チャット: 1対1の文脈を維持。
*   グループ/ルーム: 共有の文脈を維持。

### 3.3 コマンド機能
*   `/exit` または `/bye`: 会話セッションをリセットする。グループ/ルームの場合は、セッションリセット後に Bot が退出する。

### 3.4 メンション機能
グループ/ルーム内では、Bot へのメンションがある場合のみ応答する。メンション部分は AI への入力前に自動的に除去される。

### 3.5 匿名化 (v2.1)
送受信されるメッセージ内の LINE ID（ユーザーID、グループID、ルームID）を自動的に検出し、`[ID]` に置換する。

### 3.6 応答制限と分割 (v2.1)
*   1回の応答の合計文字数は最大 500 文字に制限する（AI への指示により実現）。
*   読みやすさを考慮して、160 文字（全角 20 文字 × 8 行相当）を超える場合はメッセージを分割して送信する（`LineService` にて処理）。

### 4.2 文字数・行数制御 (v2.1追加)
- **目的**: LINE の画面上での視認性を確保し、長文による圧迫感を軽減する。
- **文字数制限**: OpenAI へのシステムプロンプトで「500文字以内」を指示。
- **分割ルール**: 
    - 理由: モバイル端末の UI サイズ（半角 28 文字程度での折り返し）を考慮し、全角 20 文字 × 8 行に相当する 160 文字を閾値とする。
    - 方式: 出力テキストを 160 文字ごとに分割し、個別のメッセージとして送信する。

### 3.7 引用（リプライ）対応 (v2.1)
LINE のリプライ機能を使用してメッセージが送信された場合、Webhook イベントに含まれる `quotedMessageId` を起点に、以下の順序でリプライ元のテキストを解決して AI 入力に含める。
- まず、アプリ内インメモリのメッセージキャッシュ（直近100件）から `messageId -> text` を検索する。
- キャッシュに存在しない場合は、`MessagingApi.get_message_content(messageId)` をフォールバックとして試みる（画像/自Botメッセージ等でのみ取得できる場合がある）。
- 取得できた場合は、`引用メッセージ: "..."\n質問: ...` の形式でユーザー入力に連結する。

注: LINE API の仕様上、他ユーザーが送信したテキストは messageId から直接取得できないケースがあるため、キャッシュが一次情報源となる。

### 3.8 招待時のヘルプメッセージ (v2.1)
グループやルームに招待された際、自動的に使い方の説明を含む挨拶メッセージを送信する。


## 4. 設計上の工夫と制約（v2.1追加）

### 4.1 メッセージキャッシュと会話履歴
- **メッセージキャッシュ**: 
    - 目的: 他ユーザーのテキストに対するリプライ時、`messageId` から本文を直接取得できない仕様を補う。
    - 方式: `ChatbotLogic` 内で `messageId -> text` をインメモリ辞書に保存。上限は直近100件。
- **コンテキスト履歴**:
    - 目的: AIが直接話しかけられていない（メンションされていない）前後の会話の流れを把握できるようにする。
    - 方式: コンテキスト（ユーザー/グループ）ごとに `deque` を用いて直近10件の `(userId, text)` を保持。
    - フロー: 受信時に必ず保存 → AIへの入力メッセージの前に「直近の会話内容」として整形・挿入。
- **セキュリティ/プライバシー**:
    - キャッシュはプロセスメモリ上のみ。履歴としてAIに送信する際も、各メッセージに匿名化処理を適用。
    - ユーザーIDは末尾4文字のみを表示し、特定を困難にする。
- **将来拡張**: 永続・共有を要する場合は Redis 等の KVS への置き換えを検討。

### 4.3 コンテキスト圧縮（サマライズ） (v2.1追加)
- **目的**: 長期間の会話において、過去の重要な文脈を維持しつつ AI の処理効率（コンテキスト窓の有効活用）を高める。
- **方式**: 
    - セッション開始からメッセージ 10 件ごとに、その時点までの会話内容を AI に要約させる（`OpenAIService.summarize`）。
    - 生成された要約は、コンテキストごとに `deque` で直近 10 件まで保持する。
- **フロー**:
    1. メッセージ受信時に累計カウントをインクリメント。
    2. カウントが 10 の倍数に達した際、現在のセッション ID を用いて OpenAI に「これまでの内容の要約」を依頼。
    3. 取得したサマリーを保存。
    4. 次回以降の AI への入力プロンプトの冒頭に、保持しているサマリーを「これまでの会話の要約」として付加する。
- **効果**: `Responses API` によるセッション維持に加え、プログラム側で明示的に要約を注入することで、より長いスパンでの一貫した対話が可能になる。
